{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8178fee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mArchive\u001b[m\u001b[m/\r\n",
      "Archive.zip\r\n",
      "\u001b[34mArchive_2\u001b[m\u001b[m/\r\n",
      "\u001b[34mCOMP6721_Group_L\u001b[m\u001b[m/\r\n",
      "Euro sat - Resnet 30 epochs without weights Transfer Learning - WITH TSNE.ipynb\r\n",
      "Euro sat - Resnet 30 epochs without weights-WITH TSNE.ipynb\r\n",
      "Euro sat - Resnet 30 epochs without weights.ipynb\r\n",
      "Euro sat - Resnet 30 epochs- Transfer Learning with 13 bands.ipynb\r\n",
      "EuroSat-transfer-learning-resnet18-13.pt\r\n",
      "EuroSat-transfer-learning-resnet18-3.pt\r\n",
      "Euro_sat_VGG.ipynb\r\n",
      "PLANET_IMAGE_CLASSIFICATION DENSENET121 - TESTING DATA.ipynb\r\n",
      "PLANET_IMAGE_CLASSIFICATION RESNET - TESTING DATA.ipynb\r\n",
      "PLANET_IMAGE_CLASSIFICATION RESNET - TSNE.ipynb\r\n",
      "PLANET_IMAGE_CLASSIFICATION RESNET.ipynb\r\n",
      "PLANET_IMAGE_CLASSIFICATION VGG16 - TESTING DATA.ipynb\r\n",
      "PLANET_IMAGE_CLASSIFICATION-DENSENET121.ipynb\r\n",
      "PLANET_IMAGE_CLASSIFICATION-VGG16.ipynb\r\n",
      "\u001b[34mPlanetDataset\u001b[m\u001b[m/\r\n",
      "Satellite-image-classification-transfer-learning-resnet18.pt\r\n",
      "Satellite_Classification_using_RESNET-TSNE.ipynb\r\n",
      "Satellite_Classification_using_RESNET-oop.ipynb\r\n",
      "Satellite_Classification_using_VGG_Load_and_save_model.ipynb\r\n",
      "Testing.ipynb\r\n",
      "Transfer_Learning_Satellite_Classification_using_RESNET.ipynb\r\n",
      "Untitled.ipynb\r\n",
      "densenet.pth\r\n",
      "euro_sat_vgg_val.ipynb\r\n",
      "eurosat-densenet.pt\r\n",
      "resnet.pth\r\n",
      "rsicb_densenet.ipynb\r\n",
      "rsicb_vgg_ablative.ipynb\r\n",
      "sat_data_vgg_op.ipynb\r\n",
      "train_results.pkl\r\n",
      "train_results_densnet.pkl\r\n",
      "train_results_densnet_1.pkl\r\n",
      "train_results_vgg.pkl\r\n",
      "vgg.pth\r\n"
     ]
    }
   ],
   "source": [
    "%ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cf42db34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], device='mps:0',\n",
      "       grad_fn=<SigmoidBackward0>)\n",
      "Image predicted as  Forest\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import tarfile\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from torchvision import transforms as T, models\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image, ImageOps, ImageEnhance\n",
    "\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "d = \"cpu\"\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    d = \"mps\"\n",
    "elif torch.cuda.is_available():\n",
    "    d = \"cuda:0\"\n",
    "device = torch.device(d)\n",
    "\n",
    "print(\"Device: {}\".format(device))\n",
    "\n",
    "sat_map ={0:\"AnnualCrop\", 1:\"Forest\",2:\"HerbaceousVegetation\",3:\"Highway\",4:\"Industrial\",5:\"Pasture\",6:\"PermanentCrop\",7:\"Residential\",8:\"River\",9:\"SeaLake\"}\n",
    "model = torch.load(\"./eurosat-resnet_new.pth\")\n",
    "model.eval()\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "img = Image.open('Archive/EuroSAT/Forest/Forest_1.jpg')  # Load image as PIL.Image\n",
    "x = transform(img)  # Preprocess image\n",
    "x = x.unsqueeze(0)  # Add batch dimension\n",
    "x=x.to(device)\n",
    "output = model(x)  # Forward pass\n",
    "pred = torch.argmax(output, 1)  # Get predicted class if multi-class classification\n",
    "print(output)\n",
    "pred = output.detach().cpu().tolist()[0]\n",
    "\n",
    "\n",
    "print('Image predicted as ', sat_map[pred[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139726cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
